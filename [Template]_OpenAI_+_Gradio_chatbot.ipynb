{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOK+qzqu33qex+htLF6kwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imywong/starter_templates/blob/main/%5BTemplate%5D_OpenAI_%2B_Gradio_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Initial setup"
      ],
      "metadata": {
        "id": "5gPwDPXYFqSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI library"
      ],
      "metadata": {
        "id": "DDJNau47uRYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "6tGdHgadHHzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import OpenAI library and other modules"
      ],
      "metadata": {
        "id": "o5LLvUL2uXeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json"
      ],
      "metadata": {
        "id": "d7P5ryd8Fs3m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply your OpenAI token\n",
        "\n",
        "Note: You can sign up for a developer account with OpenAI [here](https://platform.openai.com/signup). Once you are registered, you can generate a secret key.\n",
        "\n"
      ],
      "metadata": {
        "id": "AWY-PZ4etS8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "A1Vu-d7Z6lju"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paste in your secret key when prompted\n",
        "from getpass import getpass\n",
        "OPENAI_SECRET_KEY = getpass()"
      ],
      "metadata": {
        "id": "Q4a2_LKJIQ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=OPENAI_SECRET_KEY)"
      ],
      "metadata": {
        "id": "Kr8ccRHC5CYO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 : Create a helper function to call the OpenAI API"
      ],
      "metadata": {
        "id": "f51YkIqmswV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## --> Define the system prompt"
      ],
      "metadata": {
        "id": "HIqseM5RK0TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing this will have the most impact in terms of customising your chatbot for a specific use case."
      ],
      "metadata": {
        "id": "bXKbtcggOH7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful AI Assistant\""
      ],
      "metadata": {
        "id": "qRQTs6H8K3Zc"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the chatbot memory"
      ],
      "metadata": {
        "id": "-QMvQzSjKiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt}\n",
        "  ]"
      ],
      "metadata": {
        "id": "cGLVIon_uAoP"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model parameters"
      ],
      "metadata": {
        "id": "0D5vKbscLJQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-3.5-turbo\"\n",
        "temperature = 0.7"
      ],
      "metadata": {
        "id": "iUnCdxxmLyqf"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the helper function"
      ],
      "metadata": {
        "id": "XqENYpRcLaPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_generation (prompt, history):\n",
        "\n",
        "  messages.append({\"role\":\"user\",\"content\":prompt}) # Add prompt to message before passing in\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    temperature=temperature\n",
        "  )\n",
        "\n",
        "  response = completion.choices[0].message.content\n",
        "\n",
        "  messages.append({\"role\":\"assistant\", \"content\":response}) # Append latest output to message array so context is available on next request\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "LhYpf_FStUdw"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 : Test the helper function"
      ],
      "metadata": {
        "id": "8kIBJvnRVQZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the function to make sure it is able to take the prompt and return a response."
      ],
      "metadata": {
        "id": "Pfx6aflmNtmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define your question"
      ],
      "metadata": {
        "id": "6iDOZZ8Wv61l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who was Albert Einstein?\""
      ],
      "metadata": {
        "id": "o5xOYmGku8sI"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a response"
      ],
      "metadata": {
        "id": "wml41OHrv9ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = text_generation(question,\"None\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "o8HuKFDHupL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 : Generate a simple chat UI using Gradio\n",
        "\n",
        "A UI makes it easier to demonstrate the capability to non-coders or less technical stakeholders that might feel overwhelmed when looking at a notebook.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bIK0szD3wi7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Gradio"
      ],
      "metadata": {
        "id": "xgOCBHu0z6Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "KN93ed2x2HSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "sazP6LZG0xBe"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Gradio"
      ],
      "metadata": {
        "id": "1zOgKlTM0BCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(text_generation).launch(share=True,debug=True)"
      ],
      "metadata": {
        "id": "zvZaQ0QuEXum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}